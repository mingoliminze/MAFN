{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UvklpimX5mxc",
        "outputId": "dcbce8fb-0a42-40f2-b85c-720ddffd40eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in d:\\anaconda3\\envs\\py311\\lib\\site-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (0.3.54)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (3.11.17)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (0.3.32)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-community) (2.1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.0)\n",
            "Requirement already satisfied: anyio in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9NY_m96Q5oFD",
        "outputId": "7a66b93a-5f46-487d-efb6-9b2d83a52223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in d:\\anaconda3\\envs\\py311\\lib\\site-packages (1.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from faiss-cpu) (2.1.1)\n",
            "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from faiss-cpu) (24.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "o3X0F8Eo73W4",
        "outputId": "bf18d9c8-8667-498e-a4a2-8ba53166e6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in d:\\anaconda3\\envs\\py311\\lib\\site-packages (5.25.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.8.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (1.8.0)\n",
            "Requirement already satisfied: groovy~=0.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (2.1.1)\n",
            "Requirement already satisfied: orjson~=3.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: pydub in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.11.6)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
            "Requirement already satisfied: colorama in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QcdsdLF-PCmo",
        "outputId": "46aac9bf-2f67-4c45-9a7c-c8b43baa3bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymupdf in d:\\anaconda3\\envs\\py311\\lib\\site-packages (1.25.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZiqR6Qp2M2xr",
        "outputId": "91872036-5db1-4e94-868a-ed17f6e93964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tools\n",
            "  Downloading tools-0.1.9.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pytils (from tools)\n",
            "  Downloading pytils-0.4.3.tar.gz (101 kB)\n",
            "     ---------------------------------------- 0.0/101.4 kB ? eta -:--:--\n",
            "     -------------------------------------- 101.4/101.4 kB 6.1 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: six in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from tools) (1.16.0)\n",
            "Collecting lxml (from tools)\n",
            "  Downloading lxml-5.3.2-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
            "Downloading lxml-5.3.2-cp311-cp311-win_amd64.whl (3.8 MB)\n",
            "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.6/3.8 MB 12.6 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 1.5/3.8 MB 19.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 2.8/3.8 MB 22.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.8/3.8 MB 22.1 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: tools, pytils\n",
            "  Building wheel for tools (setup.py): started\n",
            "  Building wheel for tools (setup.py): finished with status 'done'\n",
            "  Created wheel for tools: filename=tools-0.1.9-py3-none-any.whl size=46737 sha256=5e603c9d20a349f1fba4b695c439a116d96a4896e9c1d6ce6424e0b86db2df3a\n",
            "  Stored in directory: c:\\users\\minze li\\appdata\\local\\pip\\cache\\wheels\\bc\\d8\\9d\\52ad6058db295741fe0b776c0fcfdb6670036acab59ce4ccfd\n",
            "  Building wheel for pytils (pyproject.toml): started\n",
            "  Building wheel for pytils (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for pytils: filename=pytils-0.4.3-py3-none-any.whl size=32806 sha256=546a8c6d075d27e2d2119688dc464f3a371d02f165adec93020903d6af2a00cf\n",
            "  Stored in directory: c:\\users\\minze li\\appdata\\local\\pip\\cache\\wheels\\3e\\a7\\be\\135c0d4eaa74b54f43b5b0e0b30284b1c2081fe0581424408a\n",
            "Successfully built tools pytils\n",
            "Installing collected packages: pytils, lxml, tools\n",
            "Successfully installed lxml-5.3.2 pytils-0.4.3 tools-0.1.9\n"
          ]
        }
      ],
      "source": [
        "!pip install tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0wvjRAQdSKG_",
        "outputId": "2859ac2a-3e81-4661-943c-efae31187e10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in d:\\anaconda3\\envs\\py311\\lib\\site-packages (1.0.9)\n",
            "Requirement already satisfied: six in d:\\anaconda3\\envs\\py311\\lib\\site-packages (from langdetect) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "collapsed": true,
        "id": "56-N0kZsWBO_",
        "outputId": "8905c5e2-148b-4274-b733-db12946a4987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7868\n",
            "* Running on public URL: https://38d2102b3595816bb2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://38d2102b3595816bb2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import fitz  # PyMuPDF\n",
        "import gradio as gr\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import json\n",
        "\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI as LangOpenAI\n",
        "from langdetect import detect\n",
        "from langchain.schema import Document\n",
        "\n",
        "# 1. Initialize the embedding model and load the vector library\n",
        "\n",
        "embedding_model = SentenceTransformerEmbeddings(model_name='paraphrase-multilingual-MiniLM-L12-v2')\n",
        "# vector_store = FAISS.load_local(\"my_course_index\", embedding_model)\n",
        "\n",
        "# course_id, course_name, description, term, department \n",
        "df = pd.read_excel('courses.xlsx')\n",
        "\n",
        "# 2. Generate text for embedding (here only the course name and description are concatenated, metadata stored separately)\n",
        "df['text'] = df['course_name'] + \" \" + df['description']\n",
        "\n",
        "# 3. Prepare metadata and save term and department in dictionary form\n",
        "metadatas = df[['term', 'course_name', 'description']].to_dict(orient='records')\n",
        "\n",
        "# 4. Build the FAISS vector library\n",
        "vector_store = FAISS.from_texts(df['text'].tolist(), embedding_model, metadatas=metadatas)\n",
        "\n",
        "# 5. Initialize LLM\n",
        "# llm = LangOpenAI(temperature=0, openai_api_key=\"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\")  # 用于 RetrievalQA\n",
        "\n",
        "\n",
        "# Resume PDF → Text\n",
        "def extract_text_from_pdf(file_obj):\n",
        "    import fitz\n",
        "    doc = fitz.open(file_obj.name)  \n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# upload excel\n",
        "def upload_course_excel(file_obj):\n",
        "    try:\n",
        "        new_df = pd.read_excel(file_obj.name)\n",
        "\n",
        "        required_cols = {\"course_id\", \"course_name\", \"description\", \"term\", \"department\"}\n",
        "        if not required_cols.issubset(set(new_df.columns)):\n",
        "            return \"Please upload an Excel file with the following columns: course_id, course_name, description, term, department\"\n",
        "\n",
        "        new_df['text'] = new_df['course_name'].astype(str) + \" \" + new_df['description'].astype(str)\n",
        "\n",
        "        new_df = new_df[new_df['text'].notnull()]\n",
        "        new_df = new_df[new_df['text'].str.strip() != \"\"]\n",
        "\n",
        "        new_metadatas = new_df[['term', 'department', 'course_name', 'description']].to_dict(orient='records')\n",
        "\n",
        "        new_documents = [\n",
        "            Document(page_content=text, metadata=meta)\n",
        "            for text, meta in zip(new_df['text'].tolist(), new_metadatas)\n",
        "        ]\n",
        "\n",
        "        vector_store.add_documents(new_documents)\n",
        "\n",
        "        vector_store.save_local(\"my_course_index\")\n",
        "\n",
        "        return f\"✅ Successfully uploaded and added {len(new_df)} new courses to the database!\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Wrong:{str(e)}\"\n",
        "\n",
        "\n",
        "# Use ai to analyze resume content and generate summaries\n",
        "'''\n",
        "#Chatgpt\n",
        "client = OpenAI(api_key=\"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\")\n",
        "#Deepseek\n",
        "client = OpenAI(api_key=\"sk-bf08eb9cb3934015a84b08a564189e09\", base_url=\"https://api.deepseek.com\")\n",
        "'''\n",
        "\n",
        "def get_client(model_choice: str) -> OpenAI:\n",
        "    if model_choice == \"Deepseek\":\n",
        "        return OpenAI(\n",
        "            api_key=\"sk-bf08eb9cb3934015a84b08a564189e09\",\n",
        "            base_url=\"https://api.deepseek.com\"\n",
        "        )\n",
        "    elif model_choice == \"ChatGPT4\":\n",
        "        return OpenAI(\n",
        "            api_key=\"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\"  # 替换为你的 OpenAI API Key\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model choice: {model_choice}\")\n",
        "\n",
        "        \n",
        "def summarize_resume_with_gpt(resume_text, client, model):\n",
        "    prompt = f\"\"\"\n",
        "You are a career consultant. Please summarize the core content of the resume below, including:\n",
        "- Educational background\n",
        "- Skills and programming languages\n",
        "- Project experience or course experience\n",
        "- Key skills that may be missing\n",
        "Please return the summary in concise and natural language, do not list JSON or bullet points.\n",
        "The resume content is as follows:\n",
        "{resume_text}\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "def recommend_from_resume(resume_file, user_goal_text, term, num, model_choice):\n",
        "    try:\n",
        "        if user_goal_text.strip() == \"\":\n",
        "            return \"What do you want to learn?\"\n",
        "        client = get_client(model_choice)\n",
        "        # detect the language\n",
        "        try:\n",
        "            lang = detect(user_goal_text)\n",
        "        except:\n",
        "            lang = \"en\"\n",
        "\n",
        "        lang_instruction = \"请用中文回复：\" if lang.startswith(\"zh\") else \"Please respond in English:\"\n",
        "\n",
        "        \n",
        "        if model_choice==\"Deepseek\":\n",
        "            m = \"deepseek-chat\"\n",
        "        elif model_choice=='ChatGPT4':\n",
        "            m = \"gpt-4-turbo\"\n",
        "        # resume + goal    \n",
        "        if resume_file is not None:\n",
        "            resume_text = extract_text_from_pdf(resume_file)\n",
        "            resume_summary = summarize_resume_with_gpt(resume_text, client, m)\n",
        "            user_summary = f\"My background: {resume_summary}\\nMy goal:{user_goal_text}\"\n",
        "            summary_info = f\"Resume_summary：\\n{resume_summary}\\n\\n\"\n",
        "        else:\n",
        "            user_summary = f\"My goal is:{user_goal_text}\"\n",
        "            summary_info = \"(No resume uploaded, recommendation based on learning objectives only)\\n\\n\"\n",
        "\n",
        "         # Set similarity (distance) threshold(\"l like football\" with no matches)\n",
        "        SIMILARITY_THRESHOLD = 25 \n",
        "        k0=4*num\n",
        "        \n",
        "        if k0 < 10:\n",
        "            k0=10\n",
        "        matches = vector_store.similarity_search_with_score(\n",
        "            user_summary,\n",
        "            k=k0,\n",
        "            filter={\"term\": term}\n",
        "         )\n",
        "\n",
        "         # for doc, score in matches:\n",
        "         #     print(f\"matches: {doc.page_content[:50]}..., distence: {score:.3f}\")\n",
        "\n",
        "         # closest result too far away\n",
        "        if not matches or matches[0][1] > SIMILARITY_THRESHOLD:\n",
        "            return \"Sorry, our course library dones't contain relavent courses. You may upload more courses through our app.\" \n",
        "            # return matches[0][1]\n",
        " \n",
        "\n",
        "        # Extract course name and description\n",
        "        course_docs: list[Document] = [doc for doc, _ in matches]\n",
        "\n",
        "        course_names = []\n",
        "        for i, doc in enumerate(course_docs):\n",
        "            name = doc.metadata.get(\"course_name\", doc.page_content[:50])  \n",
        "            course_names.append(f\"{i+1}. {name.strip()}\")\n",
        "\n",
        "\n",
        "        # Only pass the actual courses and let it write reasons\n",
        "        course_text_block = \"\\n\".join([f\"{i+1}. {doc.page_content}\" for i, doc in enumerate(course_docs)])\n",
        "        prompt = f\"\"\"\n",
        "        {lang_instruction}.\n",
        "        \n",
        "        Below is the background information and goals: {user_summary}\n",
        "        We matched the following real courses for users (the course names are all real):\n",
        "        {course_text_block}.\n",
        "        Please select exact {num} courses from the above based on their background and goals, and explain why you recommend them. \n",
        "        Do not make up course names.Please be aware that: if there is no fit, proper courses to suggest based on the provided information, \n",
        "        please output nothing but: \"Sorry, our course library dones't contain relavent courses. You can upload more courses through our app.\" \n",
        "        If their goal is not a question for course recommendation assistant, please output nothing but: \"Sorry, your goal is not relevant to course selection.\"\n",
        "\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=m,\n",
        "            messages=[{\"role\":\"system\", \n",
        "                       \"content\":\"You are a university course recommendation assistant, aiming to give the most proper suggestion to university students to meet their goal. \"},\n",
        "                {\"role\": \"user\", \"content\": prompt}]\n",
        "        )\n",
        "        reason = response.choices[0].message.content.strip()\n",
        "\n",
        "        return f\"📝 Recommendations and Reasons :\\n{reason}\"\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Wrong:{str(e)}\"\n",
        "\n",
        "\n",
        "\n",
        "# 6. Building the Gradio interface\n",
        "term_options = [\"Fall\", \"Spring\", \"Summer\"]\n",
        "model_options = ['Deepseek', 'ChatGPT4']\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    '''\n",
        "    with gr.Tab(\"🎓 Course Recommendations\"):\n",
        "        gr.Markdown(\"### Upload resume and get course suggestions\")\n",
        "        resume_file = gr.File(label=\"Upload your resume PDF\")\n",
        "        model_choice = gr.Dropdown(choices=model_options, label=\"Please select a model\")\n",
        "        goal = gr.Textbox(label=\"Your goals\", placeholder=\"e.g., I want to study data science or quantitative finance\")\n",
        "        term = gr.Dropdown(choices=term_options, label=\"Please select a semester\")\n",
        "        recommendation_number = gr.Number(\n",
        "            value=3,          \n",
        "            label=\"Please choose the number of recommendations you want (integer only)\",\n",
        "            precision=0,  \n",
        "        )\n",
        "        \n",
        "        submit_btn = gr.Button(\"🚀 Recommend Courses\")\n",
        "        output = gr.Textbox(label=\"Recommended results\")\n",
        "        submit_btn.click(\n",
        "            fn=recommend_from_resume,\n",
        "            inputs=[resume_file, goal, term, recommendation_number, model_choice],\n",
        "            outputs=output\n",
        "        )\n",
        "'''\n",
        "    with gr.Tab(\"🎓 Course Recommendations\"):\n",
        "        gr.Markdown('<h2 style=\"text-align: center; font-size: 2em;\">Upload Resume and Get Course Suggestions</h2>')\n",
        "        resume_file = gr.File(label=\"Upload your resume PDF\")\n",
        "        model_choice = gr.Dropdown(choices=model_options, label=\"Please select a model\")\n",
        "        goal = gr.Textbox(label=\"Your goals\", placeholder=\"e.g., I want to study data science or quantitative finance (try to be specific)\")\n",
        "        term = gr.Dropdown(choices=term_options, label=\"Please select a semester\")\n",
        "        recommendation_number = gr.Number(\n",
        "            value=3,          \n",
        "            label=\"Please choose the number of recommendations you want (integer only)\",\n",
        "            precision=0)\n",
        "        submit_btn = gr.Button(\"🚀 Recommend Courses\")\n",
        "    \n",
        "        loading_animation = gr.Image(\n",
        "            visible=False,\n",
        "            height=300,\n",
        "            width=300,\n",
        "            elem_classes=\"loading-animation\",\n",
        "            show_share_button = False,\n",
        "            show_download_button = False,\n",
        "            show_label = False\n",
        "        )\n",
        "    \n",
        "        output = gr.Textbox(label=\"Recommended results\")\n",
        "\n",
        "        def recommend_with_loading(resume_file, goal_text, term, num, model_choice):\n",
        "            import random\n",
        "            r = random.randint(1, 4)\n",
        "\n",
        "\n",
        "            yield {loading_animation: gr.Image(visible=True, value=f\"line-dog{r}.gif\"), \n",
        "                   output: \"\"}\n",
        "            try:\n",
        "                result = recommend_from_resume(resume_file, goal_text, term, num, model_choice)\n",
        "                yield {\n",
        "                    loading_animation: gr.Image(visible=False),\n",
        "                    output: result\n",
        "                }\n",
        "            except Exception as e:\n",
        "                yield {\n",
        "                    loading_animation: gr.Image(visible=False),\n",
        "                    output: f\"Error: {str(e)}\"\n",
        "                }\n",
        "\n",
        "        submit_btn.click(\n",
        "            fn=recommend_with_loading,\n",
        "            inputs=[resume_file, goal, term, recommendation_number, model_choice],\n",
        "            outputs=[loading_animation, output]\n",
        "        )\n",
        "\n",
        "    \n",
        "\n",
        "    \n",
        "    with gr.Tab(\"📂 Upload new courses\"):\n",
        "        gr.Markdown(\"### Upload a course Excel file to expand the database\")\n",
        "        course_file = gr.File(label=\"Upload Excel with course_id, course_name, description, term, department\", file_types=[\".xlsx\"])\n",
        "        upload_btn = gr.Button(\"📥 Upload Course Table\")\n",
        "        upload_output = gr.Textbox(label=\"Upload Result\")\n",
        "\n",
        "        upload_btn.click(\n",
        "            fn=upload_course_excel,\n",
        "            inputs=course_file,\n",
        "            outputs=upload_output\n",
        "        )\n",
        "\n",
        "demo.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
